{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "761c4f96-04b4-4d89-9b6e-d84bcefebb64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import modules and assign pipeline parameters to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d04a7e1-e915-4864-8354-a7adf3f6ba09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import dlt\n",
    "from pyspark.sql.functions import col, when, coalesce, lit, concat\n",
    "\n",
    "# Assign pipeline parameters to variables\n",
    "catalog = spark.conf.get(\"catalog\")\n",
    "schema = spark.conf.get(\"schema\")\n",
    "volume = spark.conf.get(\"volume\")\n",
    "cleansed_table = spark.conf.get(\"cleansed_table\") # cleansed_table is the staging table\n",
    "\n",
    "volume_path = f\"/Volumes/{catalog}/{schema}/{volume}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "327a654d-bd6f-42e8-97ec-6d8f9c76c0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define a view to validate and cleanse the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "497d3210-7aea-4bfc-94d7-565175ed1d07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(\n",
    "    comment=\"A view for stage consumer complaints\"\n",
    ")\n",
    "\n",
    "# Data validations for staging table\n",
    "@dlt.expect_or_drop(\"valid_complaint_id\", \"Complaint_ID IS NOT NULL AND Complaint_ID RLIKE '^[0-9]+$' AND length(Complaint_ID) = 7\")\n",
    "@dlt.expect_or_drop(\"valid_date_received\", \"Date_received >= Date_submitted\")\n",
    "@dlt.expect(\"valid_is_timely\", \"Is_timely IN ('Yes', 'No')\")\n",
    "\n",
    "# Function to create staging table\n",
    "def stage_complaints():\n",
    "    df = spark.read.csv(volume_path, header=True, inferSchema=True)\n",
    "    \n",
    "    df = df.withColumnRenamed(\"Complaint ID\", \"Complaint_ID\") \\\n",
    "           .withColumnRenamed(\"Submitted via\", \"Submitted_via\") \\\n",
    "           .withColumnRenamed(\"Date submitted\", \"Date_submitted\") \\\n",
    "           .withColumnRenamed(\"Date received\", \"Date_received\") \\\n",
    "           .withColumn(\n",
    "               \"Sub_product\", \n",
    "               when(\n",
    "                   col(\"Sub-product\").isNull() | (col(\"Sub-product\") == \"I do not know\"), \n",
    "                   concat(lit(\"Unknown for \"), col(\"Product\"))\n",
    "                ).otherwise(col(\"Sub-product\"))\n",
    "            ) \\\n",
    "           .withColumn(\"Issue\", coalesce(col(\"Issue\"), lit(\"Unknown\"))) \\\n",
    "           .withColumn(\"Sub_issue\", coalesce(col(\"Sub-issue\"), lit(\"Unknown\"))) \\\n",
    "           .withColumn(\"Company_public_response\", coalesce(col(\"Company public response\"), lit(\"Unknown\"))) \\\n",
    "           .withColumn(\"Company_response_to_consumer\", coalesce(col(\"Company response to consumer\"), lit(\"Unknown\"))) \\\n",
    "           .withColumn(\"Is_timely\", coalesce(col(\"Timely response?\"), lit(\"Unknown\")))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9185d69-7cbe-4651-974f-786bcede0a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define a materialized view for date dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b56d44fe-ff39-488f-9720-2802afde9de6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"A materialized view for date dimension\"\n",
    ")\n",
    "\n",
    "# Function to create a date dimension from the staging table\n",
    "def dim_date():\n",
    "    return spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            Date_submitted AS Date, \n",
    "            YEAR(Date_submitted) AS Year,\n",
    "            QUARTER(Date_submitted) AS Quarter,\n",
    "            DATE_FORMAT(Date_submitted, 'MMM') AS Month, -- get month name in short form e.g. Jan\n",
    "            DAY(Date_submitted) AS Day\n",
    "        FROM LIVE.{cleansed_table}\n",
    "        UNION\n",
    "        SELECT \n",
    "            Date_received AS Date,\n",
    "            YEAR(Date_received) AS Year,\n",
    "            QUARTER(Date_received) AS Quarter,\n",
    "            DATE_FORMAT(Date_received, 'MMM') AS Month,\n",
    "            DAY(Date_received) AS Day\n",
    "        FROM LIVE.{cleansed_table}\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a85772b-b7cf-4bb5-9d77-e18fcb77a09c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define a materialized view for product dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa78aee8-e894-4c52-9aa9-76637bdfbcc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"A materialized view for product dimension\"\n",
    ")\n",
    "\n",
    "# Function to create a product dimension from the staging table\n",
    "def dim_product():\n",
    "    return spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT DISTINCT \n",
    "            Product, \n",
    "            Sub_product\n",
    "        FROM LIVE.{cleansed_table}\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e023441-9886-4887-9a15-9fbad6f2e11f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define a materialized view for the fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dc6a317-1fa4-4bcf-bc4b-106417cbc3cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"A materialized view for the fact table (dropping state and product columns)\"\n",
    ")\n",
    "\n",
    "# Function to create a fact table from the staging table\n",
    "def fact_complaints():\n",
    "    return spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            Complaint_ID,\n",
    "            Submitted_via,\n",
    "            Date_submitted,\n",
    "            Date_received,\n",
    "            Sub_product,\n",
    "            Issue,\n",
    "            Sub_issue,\n",
    "            Company_public_response,\n",
    "            Company_response_to_consumer,\n",
    "            Is_timely\n",
    "        FROM LIVE.{cleansed_table}\n",
    "        \"\"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cc-pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
